{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871a795a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'investor_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m subscription_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubscription.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheet1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Or your specific sheet name\u001b[39;00m\n\u001b[1;32m      4\u001b[0m bank_account_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBankAccount.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSheet1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Or your specific sheet name\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbank_account_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minvestor_profile_id_raw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrouting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbank #\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minvestor_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minvestor_profile_id_raw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvestor_profile_id_raw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m merged_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     15\u001b[0m     merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvestor_profile_id_raw\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/stat/lib/python3.9/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/envs/stat/lib/python3.9/site-packages/pandas/core/reshape/merge.py:794\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_on, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_left_right_on(left_on, right_on)\n\u001b[1;32m    788\u001b[0m (\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m    792\u001b[0m     left_drop,\n\u001b[1;32m    793\u001b[0m     right_drop,\n\u001b[0;32m--> 794\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_drop:\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_drop_labels_or_levels(left_drop)\n",
      "File \u001b[0;32m~/anaconda3/envs/stat/lib/python3.9/site-packages/pandas/core/reshape/merge.py:1310\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m     \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[1;32m   1309\u001b[0m     lk \u001b[38;5;241m=\u001b[39m cast(Hashable, lk)\n\u001b[0;32m-> 1310\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1311\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/stat/lib/python3.9/site-packages/pandas/core/generic.py:1911\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'investor_name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subscription_df = pd.read_excel(\"Subscription.xlsx\", sheet_name=\"Sheet1\") # Or your specific sheet name\n",
    "bank_account_df = pd.read_excel(\"BankAccount.xlsx\", sheet_name=\"Sheet1\") # Or your specific sheet name\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    bank_account_df,\n",
    "    subscription_df[['investor_profile_id_raw', 'profile', 'routing', 'bank #']],\n",
    "    left_on='investor_name',\n",
    "    right_on='investor_profile_id_raw',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "if 'investor_profile_id_raw' in merged_df.columns:\n",
    "    merged_df = merged_df.drop(columns=['investor_profile_id_raw'])\n",
    "else:\n",
    "    print(\"Column 'investor_profile_id_raw' not found in merged_df. It might have been automatically handled or named differently.\")\n",
    "\n",
    "output_excel_filename = \"Updated_BankAccount_Data.xlsx\"\n",
    "merged_df.to_excel(output_excel_filename, index=False, sheet_name=\"MergedData\")\n",
    "print(f\"\\nSuccessfully saved the updated table to '{output_excel_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1addc54",
   "metadata": {},
   "source": [
    "这个bankaccount的权限我没有所以还没改到bankaccount中\n",
    "join 的时候\n",
    "\n",
    "join之后 按照subscription 中的 profile, routing, bank # 去重的结果\n",
    "和按照原bankaccount中的 bank_account_transfer_type, bank_account_routing_number,\tbank_account_account_number去重的结果不一样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8990edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: 读取 BankAccount 的所有数据\n",
    "bank_raw = pd.read_excel(\"BankAccount.xlsx\", sheet_name=\"Sheet1\", header=None)\n",
    "\n",
    "# Step 2: 取最后一行为真正的列名\n",
    "bank_headers = bank_raw.iloc[-1]\n",
    "bank_account_df = bank_raw.iloc[:-1].copy()\n",
    "bank_account_df.columns = bank_headers\n",
    "\n",
    "# Step 3: 读取 Subscription.xlsx（正常结构）\n",
    "subscription_df = pd.read_excel(\"Subscription.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "# Step 4: 合并两个数据集\n",
    "merged_df = pd.merge(\n",
    "    bank_account_df,\n",
    "    subscription_df[['profile', 'routing', 'bank #']],\n",
    "    left_on='investor_name',\n",
    "    right_on='profile',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 5: 删除多余的列\n",
    "# if 'investor_profile_id_raw' in merged_df.columns:\n",
    "#     merged_df = merged_df.drop(columns=['investor_profile_id_raw'])\n",
    "\n",
    "#去重\n",
    "# merged_df = merged_df.drop_duplicates(\n",
    "#     subset=['profile', 'routing', 'bank #'], keep='first'\n",
    "# )\n",
    "\n",
    "# 去重：每个唯一银行账户只保留一次\n",
    "# merged_df = merged_df.drop_duplicates(\n",
    "#     subset=[\n",
    "#         'profile',\n",
    "#         'bank_account_transfer_type',\n",
    "#         'bank_account_routing_number',\n",
    "#         'bank_account_account_number'\n",
    "#     ],\n",
    "#     keep='first'\n",
    "# )\n",
    "\n",
    "# 统计每个 profile 拥有多少个唯一银行账户\n",
    "# account_count = merged_df.groupby('profile')[\n",
    "#     ['bank_account_transfer_type', 'bank_account_routing_number', 'bank_account_account_number']\n",
    "# ].nunique()\n",
    "\n",
    "# # 保留拥有多个唯一银行账户的 profile\n",
    "# multiple_accounts = account_count[\n",
    "#     (account_count['bank_account_transfer_type'] > 1) |\n",
    "#     (account_count['bank_account_routing_number'] > 1) |\n",
    "#     (account_count['bank_account_account_number'] > 1)\n",
    "# ]\n",
    "\n",
    "# # Step 6: 输出文件\n",
    "output_excel_filename = \"Updated_BankAccount_Data.xlsx\"\n",
    "merged_df.to_excel(output_excel_filename, index=False, sheet_name=\"MergedData\")\n",
    "\n",
    "# print(f\"✅ Successfully saved the updated table to '{output_excel_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff7c1656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updated_BankAccount_Highlighted.xlsx'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# 读取文件\n",
    "file_path = \"2-Updated_BankAccount_Data.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 生成唯一银行账户标识键\n",
    "df['account_key'] = (\n",
    "    df['bank_account_transfer_type'].astype(str) + \"|\" +\n",
    "    df['bank_account_routing_number'].astype(str) + \"|\" +\n",
    "    df['bank_account_account_number'].astype(str)\n",
    ")\n",
    "\n",
    "# 去重用于分析（但不用于最终高亮）\n",
    "dedup_df = df.drop_duplicates(\n",
    "    subset=['profile', 'bank_account_transfer_type', 'bank_account_routing_number', 'bank_account_account_number']\n",
    ")\n",
    "\n",
    "# 多账户的 profile（一个 profile → 多个账户）\n",
    "profile_counts = dedup_df.groupby('profile').size().reset_index(name='count')\n",
    "multi_account_profiles = set(profile_counts[profile_counts['count'] > 1]['profile'])\n",
    "\n",
    "# 多 profile 使用同一账户（一个账户 → 多个 profile）\n",
    "account_counts = dedup_df.groupby('account_key')['profile'].nunique().reset_index(name='count')\n",
    "shared_accounts = set(account_counts[account_counts['count'] > 1]['account_key'])\n",
    "\n",
    "# 打开原始 Excel 文件进行高亮\n",
    "wb = load_workbook(file_path)\n",
    "ws = wb.active\n",
    "\n",
    "# 获取列索引\n",
    "header = [cell.value for cell in next(ws.iter_rows(min_row=1, max_row=1))]\n",
    "profile_col = header.index('profile') + 1\n",
    "transfer_col = header.index('bank_account_transfer_type') + 1\n",
    "routing_col = header.index('bank_account_routing_number') + 1\n",
    "number_col = header.index('bank_account_account_number') + 1\n",
    "\n",
    "# 高亮样式\n",
    "profile_fill = PatternFill(start_color=\"FFFF00\", end_color=\"FFFF00\", fill_type=\"solid\")  # 黄色\n",
    "account_fill = PatternFill(start_color=\"00B0F0\", end_color=\"00B0F0\", fill_type=\"solid\")  # 蓝色\n",
    "\n",
    "# 从第二行开始遍历（数据行）\n",
    "for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n",
    "    profile_val = row[profile_col - 1].value\n",
    "    transfer = str(row[transfer_col - 1].value)\n",
    "    routing = str(row[routing_col - 1].value)\n",
    "    number = str(row[number_col - 1].value)\n",
    "    account_key = f\"{transfer}|{routing}|{number}\"\n",
    "\n",
    "    # 高亮 profile（黄色）\n",
    "    if profile_val in multi_account_profiles:\n",
    "        row[profile_col - 1].fill = profile_fill\n",
    "\n",
    "    # 高亮银行账户字段（蓝色）\n",
    "    if account_key in shared_accounts:\n",
    "        row[transfer_col - 1].fill = account_fill\n",
    "        row[routing_col - 1].fill = account_fill\n",
    "        row[number_col - 1].fill = account_fill\n",
    "\n",
    "# 保存高亮后的文件\n",
    "highlighted_file_path = \"Updated_BankAccount_Highlighted.xlsx\"\n",
    "wb.save(highlighted_file_path)\n",
    "\n",
    "highlighted_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aae699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取合并后的表格\n",
    "df = pd.read_excel(\"Updated_BankAccount_Data.xlsx\")\n",
    "\n",
    "# 去重：确保银行账户唯一组合不重复计数\n",
    "unique_accounts_df = df.drop_duplicates(\n",
    "    subset=['profile', 'bank_account_transfer_type', 'bank_account_routing_number', 'bank_account_account_number']\n",
    ")\n",
    "\n",
    "# 每个 profile 拥有多少个唯一银行账户\n",
    "profile_to_account_count = unique_accounts_df.groupby('profile').size().reset_index(name='unique_bank_accounts')\n",
    "\n",
    "# 找出拥有多个账户的 profile（正常情况）\n",
    "multi_accounts = profile_to_account_count[profile_to_account_count['unique_bank_accounts'] > 1]\n",
    "\n",
    "print(\"✅ 以下 profiles 拥有多个唯一银行账户：\")\n",
    "\n",
    "multi_accounts.to_excel(\"Profiles_With_Multiple_BankAccounts.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去重：确保组合唯一\n",
    "unique_accounts_df = df.drop_duplicates(\n",
    "    subset=['profile', 'bank_account_transfer_type', 'bank_account_routing_number', 'bank_account_account_number']\n",
    ")\n",
    "\n",
    "# 构建账户标识键（方便分组）\n",
    "unique_accounts_df['account_key'] = (\n",
    "    unique_accounts_df['bank_account_transfer_type'].astype(str) + \"|\" +\n",
    "    unique_accounts_df['bank_account_routing_number'].astype(str) + \"|\" +\n",
    "    unique_accounts_df['bank_account_account_number'].astype(str)\n",
    ")\n",
    "\n",
    "# 每个账户 key 对应多少个不同的 profile\n",
    "account_to_profile_count = unique_accounts_df.groupby('account_key')['profile'].nunique().reset_index(name='profile_count')\n",
    "\n",
    "# 找出被多个 profile 共享的银行账户\n",
    "shared_accounts = account_to_profile_count[account_to_profile_count['profile_count'] > 1]\n",
    "\n",
    "print(\"⚠️ 以下银行账户被多个 profiles 使用（可能是夫妻共享账户等情况）：\")\n",
    "print(shared_accounts)\n",
    "\n",
    "shared_accounts.to_excel(\"BankAccounts_Shared_By_Multiple_Profiles.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
